{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "yCbjd_9Ros6D"
      },
      "source": [
        "# 머신 러닝 교과서 - 파이토치편"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-itZ1LYos6E"
      },
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/ml-with-pytorch/blob/main/ch15/ch15_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3OKUWS3os6F"
      },
      "source": [
        "## 패키지 버전 체크"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYoVZZAHos6F"
      },
      "source": [
        "check_packages.py 스크립트에서 로드하기 위해 폴더를 추가합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rcWuHauzos6F",
        "outputId": "1acee851-fb31-4b93-d5ef-e1f495ce6563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-19 07:10:35--  https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/python_environment_check.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1629 (1.6K) [text/plain]\n",
            "Saving to: ‘python_environment_check.py’\n",
            "\n",
            "python_environment_ 100%[===================>]   1.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-19 07:10:35 (35.5 MB/s) - ‘python_environment_check.py’ saved [1629/1629]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# 코랩의 경우 깃허브 저장소로부터 python_environment_check.py를 다운로드 합니다.\n",
        "if 'google.colab' in sys.modules:\n",
        "    !wget https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/python_environment_check.py\n",
        "else:\n",
        "    sys.path.insert(0, '..')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfyZvq7Wos6H"
      },
      "source": [
        "**주의**: 책에 있는 코드를 재현하려면 이 장에서 사용한 패키지인 `torchtext` 0.10.0(https://pypi.org/project/torchtext/0.10.0/) 버전을 사용해야 합니다.\n",
        "\n",
        "이 노트북에는 최신 버전의 `torchtext`를 사용하려면 몇 가지를 수정해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JHknaWZmos6H"
      },
      "outputs": [],
      "source": [
        "# pip install torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP0YTIOPos6H"
      },
      "source": [
        "최신 버전의 `torchtext`를 사용하려면 `portalocker`가 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g-nBse4pos6H",
        "outputId": "92e37694-4809-47dc-9001-7a29d7745db3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker==2.1.0\n",
            "  Downloading portalocker-2.1.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install portalocker==2.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9SrydFRos6G"
      },
      "source": [
        "권장 패키지 버전을 확인하세요:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "egu2MOufos6G",
        "outputId": "6ed0f73c-f15f-410b-d180-09c8debf3e0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Your Python version is 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "[OK] torch 2.0.1+cu118\n",
            "[OK] torchtext 0.15.2+cpu\n"
          ]
        }
      ],
      "source": [
        "from python_environment_check import check_packages\n",
        "\n",
        "\n",
        "d = {\n",
        "    'torch': '1.8.0',\n",
        "    'torchtext': '0.10.0'\n",
        "}\n",
        "check_packages(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgX48KNhos6G"
      },
      "source": [
        "# 15장 - 순환 신경망으로 순차 데이터 모델링 (파트 2/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NcLcT2oos6G"
      },
      "source": [
        "**목차**\n",
        "\n",
        "- 파이토치로 시퀀스 모델링을 위한 RNN 구현\n",
        "  - 첫 번째 프로젝트: IMDb 영화 리뷰의 감성 분석\n",
        "    - 영화 리뷰 데이터 준비\n",
        "    - 문장 인코딩을 위한 임베딩 층\n",
        "    - RNN 모델 만들기\n",
        "    - 감성 분석 작업을 위한 RNN 모델 만들기\n",
        "      - 양방향 RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7jCt27uFos6G"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kbn_pv7os6H"
      },
      "source": [
        "# 파이토치로 시퀀스 모델링을 위한 RNN 구현\n",
        "\n",
        "## 첫 번째 프로젝트: IMDb 영화 리뷰의 감성 분석\n",
        "\n",
        "### 영화 리뷰 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LVVfKJDWos6H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tLSBYQNmos6I"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "# 단계 1: 데이터셋을 로드합니다\n",
        "\n",
        "train_dataset = IMDB(split='train')\n",
        "test_dataset = IMDB(split='test')\n",
        "\n",
        "# test_dataset = list(test_dataset)   #datapipe to list\n",
        "\n",
        "torch.manual_seed(1)\n",
        "train_dataset, valid_dataset = random_split(\n",
        "    list(train_dataset), [20000, 5000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6PEWHQVoos6I",
        "outputId": "a9bc923a-45c4-4f12-bc3c-5ebf5a9bd9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어휘 사전 크기: 69023\n"
          ]
        }
      ],
      "source": [
        "## 단계 2: 고유 토큰 (단어) 찾기\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "token_counts = Counter()\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
        "        ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = text.split()\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "for label, line in train_dataset:\n",
        "    tokens = tokenizer(line)\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "\n",
        "print('어휘 사전 크기:', len(token_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lkd_ks7Wos6I",
        "outputId": "9f064122-f17b-4a45-d054-777210a72869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 7, 35, 457]\n"
          ]
        }
      ],
      "source": [
        "## 단계 3: 고유 토큰을 정수로 인코딩하기\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "vocab = vocab(ordered_dict)\n",
        "\n",
        "vocab.insert_token(\"<pad>\", 0)\n",
        "vocab.insert_token(\"<unk>\", 1)\n",
        "vocab.set_default_index(1)\n",
        "\n",
        "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xTOXkt4gos6I"
      },
      "outputs": [],
      "source": [
        "if not torch.cuda.is_available():\n",
        "    print(\"경고: 이 코드는 CPU에서 매우 느릴 수 있습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BNNuqvjpos6I"
      },
      "outputs": [],
      "source": [
        "## 단계 3-A: 변환 함수 정의\n",
        "import torchtext\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "\n",
        "from torchtext import __version__ as torchtext_version\n",
        "from pkg_resources import parse_version\n",
        "\n",
        "if parse_version(torchtext.__version__) > parse_version(\"0.10\"):\n",
        "    label_pipeline = lambda x: 1. if x == 2 else 0.         # 1 ~ 부정 리뷰, 2 ~ 긍정 리뷰\n",
        "else:\n",
        "    label_pipeline = lambda x: 1. if x == 'pos' else 0.\n",
        "\n",
        "\n",
        "## 단계 3-B: 인코딩과 변환 함수 감싸기\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text),\n",
        "                                      dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
        "        text_list, batch_first=True)\n",
        "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X9kCgbEOos6I",
        "outputId": "bb3ff339-2f3c-4935-e491-ca4f92005e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
            "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
            "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
            "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
            "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
            "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
            "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
            "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
            "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
            "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
            "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
            "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
            "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
            "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
            "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
            "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
            "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
            "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
            "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
            "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
            "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
            "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
            "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
            "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
            "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
            "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
            "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
            "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
            "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
            "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
            "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
            "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
            "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
            "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
            "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
            "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
            "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
            "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
            "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
            "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
            "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
            "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
            "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
            "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
            "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
            "            24,   887,    32,    31,    19,     8,    13,   428],\n",
            "        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
            "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
            "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
            "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
            "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
            "         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
            "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
            "         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
            "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
            "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
            "           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
            "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
            "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
            "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
            "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
            "       device='cuda:0')\n",
            "tensor([1., 1., 1., 0.], device='cuda:0')\n",
            "tensor([165,  86, 218, 145], device='cuda:0')\n",
            "torch.Size([4, 218])\n"
          ]
        }
      ],
      "source": [
        "## 작은 배치를 만듭니다.\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
        "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
        "print(text_batch)\n",
        "print(label_batch)\n",
        "print(length_batch)\n",
        "print(text_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M4zDK9cbos6I"
      },
      "outputs": [],
      "source": [
        "## 단계 4: 데이터셋 배치 만들기\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, collate_fn=collate_batch)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                      shuffle=False, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rQtkeXjos6J"
      },
      "source": [
        "### 문장 인코딩을 위한 임베딩 층\n",
        "\n",
        " * `input_dim`: 단어 수, i.e. 정수 인덱스 최댓값 + 1.\n",
        " * `output_dim`:\n",
        " * `input_length`: (패딩된) 시퀀스 길이\n",
        "    * 예를 들어, `'This is an example' -> [0, 0, 0, 0, 0, 0, 3, 1, 8, 9]`   \n",
        "    => input_lenght는 10\n",
        " * 층을 호출할 때 정수 값을 입력으로 받고 임베딩 층이 정수를 `[output_dim]` 크기의 실수 벡터로 바꿉니다.\n",
        "   * 입력 크기가 `[BATCH_SIZE]`이면, 출력 크기는 `[BATCH_SIZE, output_dim]`가 됩니다.\n",
        "   * 입력 크기가 `[BATCH_SIZE, 10]`이면, 출력 크기는 `[BATCH_SIZE, 10, output_dim]`가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n0UA30mqos6J",
        "outputId": "5ed72b98-e1bf-4852-9525-da07d65af814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_10.png\" width=\"600\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "Image(url='https://raw.githubusercontent.com/rickiepark/ml-with-pytorch/main/ch15/figures/15_10.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vLLGq2a5os6J",
        "outputId": "c0a42f4f-1bbc-435f-d716-0215eedf7ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.7039, -0.8321, -0.4651],\n",
            "         [-0.3203,  2.2408,  0.5566],\n",
            "         [-0.4643,  0.3046,  0.7046],\n",
            "         [-0.7106, -0.2959,  0.8356]],\n",
            "\n",
            "        [[-0.4643,  0.3046,  0.7046],\n",
            "         [ 0.0946, -0.3531,  0.9124],\n",
            "         [-0.3203,  2.2408,  0.5566],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "embedding = nn.Embedding(num_embeddings=10,\n",
        "                         embedding_dim=3,\n",
        "                         padding_idx=0)\n",
        "\n",
        "# 네 개의 인덱스를 가진 두 개의 샘플로 구성된 배치\n",
        "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
        "print(embedding(text_encoded_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIOilB2Qos6J"
      },
      "source": [
        "### RNN 모델 만들기\n",
        "\n",
        "* **RNN layers:**\n",
        "  * `nn.RNN(input_size, hidden_size, num_layers=1)`\n",
        "  * `nn.LSTM(..)`\n",
        "  * `nn.GRU(..)`\n",
        "  * `nn.RNN(input_size, hidden_size, num_layers=1, bidirectional=True)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9jeVvyySos6J",
        "outputId": "09ca642f-bb24-4d89-f77b-724d09a263a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3183],\n",
              "        [ 0.1230],\n",
              "        [ 0.1772],\n",
              "        [-0.1052],\n",
              "        [-0.1259]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "## 간단한 RNN 층을 사용한 RNN 모델 구축 예제\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size,\n",
        "                          hidden_size,\n",
        "                          num_layers=2,\n",
        "                          batch_first=True)\n",
        "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, hidden = self.rnn(x)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = RNN(64, 32)\n",
        "\n",
        "print(model)\n",
        "\n",
        "model(torch.randn(5, 3, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jor6xakUos6J"
      },
      "source": [
        "### 감성 분석 작업을 위한 RNN 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0Y9p4CVuos6J"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,\n",
        "                                      embed_dim,\n",
        "                                      padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
        "                           batch_first=True)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
        "        out, (hidden, cell) = self.rnn(out)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BCF7f6p9os6J"
      },
      "outputs": [],
      "source": [
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    for text_batch, label_batch, lengths in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(text_batch, lengths)[:, 0]\n",
        "        loss = loss_fn(pred, label_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "        total_loss += loss.item()*label_batch.size(0)\n",
        "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for text_batch, label_batch, lengths in dataloader:\n",
        "            pred = model(text_batch, lengths)[:, 0]\n",
        "            loss = loss_fn(pred, label_batch)\n",
        "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "            total_loss += loss.item()*label_batch.size(0)\n",
        "    return total_acc/len(list(dataloader.dataset)), total_loss/len(list(dataloader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Gwr5p12bos6K",
        "outputId": "38b7919a-92c2-49b1-cfa1-21bb2f04e236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 0 정확도: 0.9563 검증 정확도: 0.8582\n",
            "에포크 1 정확도: 0.9711 검증 정확도: 0.8672\n",
            "에포크 2 정확도: 0.9760 검증 정확도: 0.8714\n",
            "에포크 3 정확도: 0.9816 검증 정확도: 0.8692\n",
            "에포크 4 정확도: 0.9819 검증 정확도: 0.8666\n",
            "에포크 5 정확도: 0.9831 검증 정확도: 0.8640\n",
            "에포크 6 정확도: 0.9885 검증 정확도: 0.8612\n",
            "에포크 7 정확도: 0.9913 검증 정확도: 0.8576\n",
            "에포크 8 정확도: 0.9943 검증 정확도: 0.8570\n",
            "에포크 9 정확도: 0.9940 검증 정확도: 0.8586\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    acc_train, loss_train = train(train_dl)\n",
        "    acc_valid, loss_valid = evaluate(valid_dl)\n",
        "    print(f'에포크 {epoch} 정확도: {acc_train:.4f} 검증 정확도: {acc_valid:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UoVkqwdaos6K",
        "outputId": "d47c1bf1-c3a2-4eb0-ff1f-afd669890c85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 정확도: 0.8494\n"
          ]
        }
      ],
      "source": [
        "acc_test, _ = evaluate(test_dl)\n",
        "print(f'테스트 정확도: {acc_test:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlBVUcdKos6K"
      },
      "source": [
        "#### 양방향 RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XygmgeM9os6K"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,\n",
        "                                      embed_dim,\n",
        "                                      padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
        "                           batch_first=True, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_size*2, fc_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
        "        _, (hidden, cell) = self.rnn(out)\n",
        "        out = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vWefjEY1os6K",
        "outputId": "f54cd7de-5f3a-491a-9461-250d5bf899aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 0 정확도: 0.6254 검증 정확도: 0.7030\n",
            "에포크 1 정확도: 0.7802 검증 정확도: 0.7444\n",
            "에포크 2 정확도: 0.8495 검증 정확도: 0.8462\n",
            "에포크 3 정확도: 0.8912 검증 정확도: 0.8384\n",
            "에포크 4 정확도: 0.9315 검증 정확도: 0.8546\n",
            "에포크 5 정확도: 0.9522 검증 정확도: 0.8546\n",
            "에포크 6 정확도: 0.9700 검증 정확도: 0.8700\n",
            "에포크 7 정확도: 0.9792 검증 정확도: 0.8448\n",
            "에포크 8 정확도: 0.9857 검증 정확도: 0.8668\n",
            "에포크 9 정확도: 0.9943 검증 정확도: 0.8664\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    acc_train, loss_train = train(train_dl)\n",
        "    acc_valid, loss_valid = evaluate(valid_dl)\n",
        "    print(f'에포크 {epoch} 정확도: {acc_train:.4f} 검증 정확도: {acc_valid:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LJDBchIeos6K"
      },
      "outputs": [],
      "source": [
        "test_dataset = IMDB(split='test')\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9QE9J_knos6K",
        "outputId": "1d25efc0-9256-4441-8ffe-10e9a9e58c4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 정확도: 0.8480\n"
          ]
        }
      ],
      "source": [
        "acc_test, _ = evaluate(test_dl)\n",
        "print(f'테스트 정확도: {acc_test:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}